# Customize Dataset

## Introduction

To create your own customized dataset, you need to **STRICTLY** follow these regulations:

> 1. Dataset classes and other scripts are stored in python files.
>
> 1. All datasets should be stored in the folder `dataset` **unless** the `filepath` of the dataset is specified in the configuration
>
> 2. Except for the Dataset class, all other preprocess functions or classes are recommended to save with Dataset in the same file, you know, researches are not only challenges to our intelligence but also to our taste of beauty and tidy.
>
> 3. **DO NOT ADD** any executable console scripts into Dataset file, for instance: `print()`,`plt.show()`... all kinds of executable console scripts all forbidden in the file.
>
> 4. **You need to refresh the** `__init__.py` after you add your customized Dataset to make sure `import` works normally.

## Create Your Dataset

To create your Dataset, you need to create a single python file under the path of folder `dataset` such as `dataset/exampledata.py` or anywhere else if you specify the `filepath` in the configuration

And all Dataset class are stored within your Dataset file `dataset/exampledata.py`, Here we give you an example about the customized Dataset class

```python
from torch.utils.data import Dataset
import torch
import numpy as np
class HailingDataset_Pos(Dataset):
    def __init__(self,datapath=''):
        '''
        ## Dataset Example
        - Args:
            - datapath: The datapth of the data, default to be ''
        - Output:
            - Image, shape: [], dtype: nparray -> torch.tensor, other informations
            - Label, shape: [], dtype: nparray -> torch.tensor, other informations
        '''
        self.datapath=datapath
        self.data=self.__Init()
    def __len__(self):
        return len(self.data)
    def __getitem__(self, index):
        image=torch.from_numpy(self.data[index]['img'])
        label=torch.from_numpy(self.data[index]['label'])
        return image,label
    def __Init(self):
        with open(self.datapath,'r')as f:
            data=f.readlines()
        return data
```

## Other Preprocessing Scripts

For example, you can add other preprocess functions or classes in the same file (example from `HailingData.py`):

```python
import numba
import numpy as np
@numba.jit
def pattern_data_1T(event,shape=(10,10,40,3)):
    """## Convert the Original Hailing Data into Pattern Image with specified shape
    - Args:
        - event: Single Hailing original data
        - shape: The shape of the pattern data. Defaults to (10,10,40,3) for 1TeV data, or (10,10,50,3) for 10TeV data
    - Returns:
        - Converted Pattern Image with specified shape, dtype: nparray
    """
    pattern=np.zeros(shape)
    for i in range(len(event)):
        pattern[int(event[i][0])][int(event[i][1])][int(event[i][2])]=event[i][3:]
    return pattern
```
